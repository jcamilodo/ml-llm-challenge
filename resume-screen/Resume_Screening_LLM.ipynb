{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syDESFXUcMfV",
        "outputId": "deed3190-af75-40cd-bd48-db477644d2eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.4/288.4 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU python-dotenv\n",
        "!pip install -qU langchain\n",
        "!pip install -qU langchain_openai\n",
        "!pip install -qU pypdf\n",
        "!pip install -qU langchain_community\n",
        "!pip install -qU unstructured\n",
        "!pip install -qU chromadb\n",
        "!pip install -qU PyPDF2\n",
        "!pip install -qU langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "9WRlx_4vj7hT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import PyPDF2\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.schema import Document\n",
        "from textwrap import dedent\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "#vector database\n",
        "from langchain.vectorstores.chroma import Chroma\n",
        "#from langchain_chroma import Chroma\n",
        "#import chromadb\n"
      ],
      "metadata": {
        "id": "_Fverrr-fM3w"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', model_kwargs={'device': 'cpu'})\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=os.environ['OPENAI_API_KEY'])"
      ],
      "metadata": {
        "id": "SzJjAEhEjfyj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", max_tokens=4000, temperature=0, api_key=os.environ['OPENAI_API_KEY'])\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini-2024-07-18\", max_tokens=10000, temperature=0, api_key=os.environ['OPENAI_API_KEY'])"
      ],
      "metadata": {
        "id": "ErKD9Kidj26X"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preparar_docs(pdf_docs):\n",
        "    docs = []\n",
        "    metadata = []\n",
        "    content = []\n",
        "\n",
        "    for pdf in pdf_docs:\n",
        "\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf)\n",
        "        for index, text in enumerate(pdf_reader.pages):\n",
        "            doc_page = {'title': pdf + \" page \" + str(index + 1),\n",
        "                        'content': pdf_reader.pages[index].extract_text()}\n",
        "            docs.append(doc_page)\n",
        "    for doc in docs:\n",
        "        content.append(doc[\"content\"])\n",
        "        metadata.append({\n",
        "            \"title\": doc[\"title\"]\n",
        "        })\n",
        "    print(\"Contenido y Metadatos extraidos desde los documentos\")\n",
        "    return content, metadata\n",
        "\n",
        "def get_text_chunks(content, metadata):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=512,\n",
        "    )\n",
        "    split_docs = text_splitter.create_documents(content, metadatas=metadata)\n",
        "    print(f\"Documentos se separan en {len(split_docs)} partes\")\n",
        "    return split_docs\n"
      ],
      "metadata": {
        "id": "KhVEdD4l0XE1"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf_to_db(split_docs):\n",
        "  DB_CHROMA_PATH = 'vectorstore/'\n",
        "  db = Chroma.from_documents(documents=split_docs, embedding=embeddings,\n",
        "                             persist_directory=DB_CHROMA_PATH)\n",
        "\n",
        "  db.persist()\n",
        "  return db"
      ],
      "metadata": {
        "id": "KgucWEMnPkXo"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_folder = 'CVs'"
      ],
      "metadata": {
        "id": "epxDcAHD08hF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_archivos = [\n",
        "        f'/content/{pdf_folder}/CV1.pdf',\n",
        "        f'/content/{pdf_folder}/CV2.pdf',\n",
        "        f'/content/{pdf_folder}/CV3.pdf',\n",
        "        f'/content/{pdf_folder}/CV4.pdf',\n",
        "        f'/content/{pdf_folder}/CV5.pdf',\n",
        "        f'/content/{pdf_folder}/CV6.pdf',\n",
        "        f'/content/{pdf_folder}/CV7.pdf',\n",
        "        f'/content/{pdf_folder}/CV8.pdf',\n",
        "        f'/content/{pdf_folder}/CV9.pdf'\n",
        "]"
      ],
      "metadata": {
        "id": "jNN5Yrt307e3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding(new_file_trunk, new_file_pdf_path, file_persistent_dir_path):\n",
        "  print(f\"Creando los embedding para {file_persistent_dir_path}\")\n",
        "  #lectura simple de la informacion de los PDF\n",
        "  pdf_reader = PdfReader(new_file_pdf_path)\n",
        "  text = \"\"\n",
        "  for page in pdf_reader.pages:\n",
        "      text += page.extract_text()\n",
        "\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "      chunk_size=1000,\n",
        "      chunk_overlap=200,\n",
        "      length_function=len)\n",
        "\n",
        "  chunks = text_splitter.split_text(text=text)\n",
        "\n",
        "  new_chunks = [Document(page_content=chunk) for chunk in chunks]\n",
        "\n",
        "  db = Chroma.from_documents(\n",
        "      documents=new_chunks, embedding=embeddings, persist_directory=file_persistent_dir_path)\n",
        "\n",
        "  db.persist()"
      ],
      "metadata": {
        "id": "x43AxWFu-4o2"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_path in lista_archivos:\n",
        "  new_file_trunk = file_path[:-len(\".pdf\")]\n",
        "  create_embedding(new_file_trunk, file_path, os.path.join(\"data\", new_file_trunk))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egPAqSiq-2Sv",
        "outputId": "1a78effe-feb3-4af4-c1b4-ee54078f57cf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creando los embedding para /content/CVs/CV1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-c4368e271e55>:21: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  db.persist()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creando los embedding para /content/CVs/CV2\n",
            "Creando los embedding para /content/CVs/CV3\n",
            "Creando los embedding para /content/CVs/CV4\n",
            "Creando los embedding para /content/CVs/CV5\n",
            "Creando los embedding para /content/CVs/CV6\n",
            "Creando los embedding para /content/CVs/CV7\n",
            "Creando los embedding para /content/CVs/CV8\n",
            "Creando los embedding para /content/CVs/CV9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DB_final = Chroma(embedding_function=embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGFbi_jK3eY5",
        "outputId": "2d84393f-e9da-44dc-f7bb-292747ec5663"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-f68cf0d3466b>:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
            "  DB_final = Chroma(embedding_function=embeddings)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lista_folder = [os.path.join(\"CVs\", filename[:-len(\".pdf\")] ) for filename in lista_archivos]\n",
        "lista_folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpSFNSXmCxPa",
        "outputId": "205fd2e4-88b3-4a94-c83b-8937f09a0151"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/CVs/CV1',\n",
              " '/content/CVs/CV2',\n",
              " '/content/CVs/CV3',\n",
              " '/content/CVs/CV4',\n",
              " '/content/CVs/CV5',\n",
              " '/content/CVs/CV6',\n",
              " '/content/CVs/CV7',\n",
              " '/content/CVs/CV8',\n",
              " '/content/CVs/CV9']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lista_folder = [os.path.join(\"CVs\", filename[:-len(\".pdf\")] ) for filename in lista_archivos]\n",
        "for db_path in lista_folder:\n",
        "    print(f\"Cargando documentos desde {db_path}\")\n",
        "    # Cargar las documentos existentes en la base de datos vectoriales .\n",
        "    DB_aux = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
        "    DB_aux_data = DB_aux._collection.get(include=['documents','metadatas','embeddings'])\n",
        "    DB_final._collection.add(\n",
        "          embeddings=DB_aux_data['embeddings'],\n",
        "          metadatas=DB_aux_data['metadatas'],\n",
        "          documents=DB_aux_data['documents'],\n",
        "          ids=DB_aux_data['ids'])\n"
      ],
      "metadata": {
        "id": "wfJNtdhH4AwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = DB_final.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": len(lista_archivos)})"
      ],
      "metadata": {
        "id": "ZIQbHVTFDX9x"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1hwEuPgDYk2",
        "outputId": "55eff766-6f22-4793-ff4e-4214f2b7e020"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x796111111810>, search_kwargs={'k': 9})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = ConversationalRetrievalChain.from_llm(llm, retriever, return_source_documents=True)"
      ],
      "metadata": {
        "id": "Z15wkV-5DwFk"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Experience in Machine Learning\"\n",
        "prompt = dedent (\"\"\"You are an expert recruiter.\n",
        "  Based on the context return output string with the following JSON structure, the following structure:\n",
        "  [\n",
        "    {\n",
        "      \"name\": CV name\n",
        "      \"email\": CV email\n",
        "      \"contact_phone\": CV phone\n",
        "      \"years_of_experience\": CV Years of experience\n",
        "      \"skills\": list of skills in CV\n",
        "      \"ai_skills\": CV evaluate if candidate has experience in any branchs of Artificial Intelligence (AI, ML, GenAI). Yes/No.\n",
        "      \"score\": Evaluate between 1 and 10 the score related to requeriments in question\n",
        "    }\n",
        "  ]\n",
        "  context = Give information about CV.\n",
        "  question = \"\"\" +query+\"\"\".\n",
        "  If no matches are found, return the empty list.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "9sFGnZJOFhwk"
      },
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str_json_data = None\n",
        "with get_openai_callback() as cb:\n",
        "    response = chain({'question': prompt, 'chat_history': ''})\n",
        "    str_json_data = response['answer']\n",
        "    #print(response)\n",
        "#str_json_data"
      ],
      "metadata": {
        "id": "s13X-cjE00L7"
      },
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str_json_data = str_json_data.replace(\"```json\", '\"')\n",
        "str_json_data = str_json_data.replace(\"```\", '\"')\n",
        "if str_json_data[0] == '\"':\n",
        "  str_json_data = str_json_data[1:]\n",
        "if str_json_data[-1] == '\"':\n",
        "  str_json_data = str_json_data[:-1]\n",
        "str_json_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "loSnChupittS",
        "outputId": "d9ef6f2e-9fd0-46e8-be58-f0795695144b"
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[\\n  {\\n    \"name\": \"Alice Clark\",\\n    \"email\": \"Email me on Indeed\",\\n    \"contact_phone\": \"Not provided\",\\n    \"years_of_experience\": \"20+ years\",\\n    \"skills\": [\\n      \"data handling\",\\n      \"design\",\\n      \"development\",\\n      \"data analysis\",\\n      \"star/snowflake schema data modelling\",\\n      \"database designing\",\\n      \"scalability\",\\n      \"back-up and recovery\",\\n      \"writing and optimizing SQL code\",\\n      \"Stored Procedures\",\\n      \"creating functions\",\\n      \"views\",\\n      \"triggers\",\\n      \"indexes\",\\n      \"Microsoft Azure cloud services\",\\n      \"Document DB\",\\n      \"SQL Azure\",\\n      \"Stream Analytics\",\\n      \"Event hub\",\\n      \"Power BI\",\\n      \"Web Job\",\\n      \"Web App\",\\n      \"Azure data lake analytics (U-SQL)\",\\n      \"big data processing\",\\n      \"Azure data factory\"\\n    ],\\n    \"ai_skills\": \"Yes\",\\n    \"score\": 8\\n  }\\n]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_data = json.loads(str_json_data)\n",
        "for data in json_data:\n",
        "    print(json.dumps(data, indent=2))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJVfCKiYTs50",
        "outputId": "2bfe3239-9bd0-48fe-fd4f-13575ceb3d17"
      },
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"Alice Clark\",\n",
            "  \"email\": \"Email me on Indeed\",\n",
            "  \"contact_phone\": \"Not provided\",\n",
            "  \"years_of_experience\": \"20+ years\",\n",
            "  \"skills\": [\n",
            "    \"data handling\",\n",
            "    \"design\",\n",
            "    \"development\",\n",
            "    \"data analysis\",\n",
            "    \"star/snowflake schema data modelling\",\n",
            "    \"database designing\",\n",
            "    \"scalability\",\n",
            "    \"back-up and recovery\",\n",
            "    \"writing and optimizing SQL code\",\n",
            "    \"Stored Procedures\",\n",
            "    \"creating functions\",\n",
            "    \"views\",\n",
            "    \"triggers\",\n",
            "    \"indexes\",\n",
            "    \"Microsoft Azure cloud services\",\n",
            "    \"Document DB\",\n",
            "    \"SQL Azure\",\n",
            "    \"Stream Analytics\",\n",
            "    \"Event hub\",\n",
            "    \"Power BI\",\n",
            "    \"Web Job\",\n",
            "    \"Web App\",\n",
            "    \"Azure data lake analytics (U-SQL)\",\n",
            "    \"big data processing\",\n",
            "    \"Azure data factory\"\n",
            "  ],\n",
            "  \"ai_skills\": \"Yes\",\n",
            "  \"score\": 8\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}